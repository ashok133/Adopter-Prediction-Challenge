{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NN2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"metadata":{"id":"V1rh8exUxxpk","colab_type":"text"},"cell_type":"markdown","source":["\n","## **Adopter Prediction Challenge**\n","\n"," ~ Ankita, Ashok, Kaydee, Young\n"," \n"," ---\n","\n","Website XYZ, a music-listening social networking website, follows the “freemium” business model. The website offers basic services for free, and provides a number of additional premium capabilities for a monthly subscription fee. We are interested in predicting which people would be likely to convert from free users to premium subscribers in the next 6 month period, if they are targeted by our promotional campaign.\n","\n","### Dataset\n","\n","We have a dataset from the previous marketing campaign which targeted a number of non-subscribers.\n","\n","Features: \n","\n","```\n","1.   adopter (predictor class)\n","2.   user_id\n","3.   age\n","4.   male\n","5.   friend_cnt\n","6.   avg_friend_age\n","7.   avg_friend_male\n","8.   friend_country_cnt\n","9.   subscriber_friend_cnt\n","10.   songsListened\n","11.   lovedTracks\n","12.   posts\n","13.   playlists\n","14.   shouts\n","15.   good_country\n","16.   tenure\n","17.   *other delta variables*\n","```\n","\n","\n","\n","### Task\n","\n","The task is to build the best predictive model for the next marketing campaign, i.e., for predicting likely `adopters` (that is, which current non- subscribers are likely to respond to the marketing campaign and sign up for the premium service within 6 months after the campaign).\n","\n","---"]},{"metadata":{"id":"c0lAOQ2b0Xvf","colab_type":"text"},"cell_type":"markdown","source":["### EDA\n","\n","Performing some rudimentary EDA"]},{"metadata":{"id":"7BFSsGGrrAWo","colab_type":"code","outputId":"3abc82d5-35c6-414a-aa00-6433a5c86204","executionInfo":{"status":"ok","timestamp":1554910184541,"user_tz":240,"elapsed":4716,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"cell_type":"code","source":["!pip3 install sklearn"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.20.3)\n","Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.14.6)\n","Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.1.0)\n"],"name":"stdout"}]},{"metadata":{"id":"z5jYBuZXxrl-","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import math\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","from keras.layers.normalization import BatchNormalization\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from keras.regularizers import l1\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import cross_val_score, train_test_split,  KFold\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import StandardScaler\n","from keras.layers.advanced_activations import PReLU\n","\n","from sklearn.decomposition import PCA\n","\n","from google.colab import drive\n","\n","from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, classification_report, recall_score, f1_score, accuracy_score, precision_score\n","\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Qbw2hXELhkxW","colab_type":"code","colab":{}},"cell_type":"code","source":["# setting fixed seed value for consistency in results\n","seed = 7\n","np.random.seed(seed)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"biD6vPF8wkO_","colab_type":"code","outputId":"55c0a647-19c9-4619-a026-1a63f61b09d5","executionInfo":{"status":"ok","timestamp":1555039045136,"user_tz":240,"elapsed":1689,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["# drive.mount('/content/drive/')\n","\n","# original dataset\n","data = pd.read_csv('https://drive.google.com/uc?export=view&id=1wctM0dYDj839zp6sTlFnDgCmFspXhDuW')\n","\n","# rose_data from the R script\n","# data = pd.read_csv('https://drive.google.com/uc?export=view&id=14wilOFigXttteZAt5oUHT9fh1m5LhnJj')\n","\n","data.adopter.value_counts()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    85142\n","1     1540\n","Name: adopter, dtype: int64"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"colab_type":"text","id":"_aO0dQjzkuZc"},"cell_type":"markdown","source":["# PCA\n","\n","The neural net is overfitting for either of the classes (regardless of the sample ration). We'll try extracting top x important features to reduce the number of dimensions our net has to deal with."]},{"metadata":{"colab_type":"code","id":"OC4tc2kWkseR","colab":{}},"cell_type":"code","source":["# # Let's reduce the feature space to 10 Principal Components\n","# pca = PCA(n_components=2, svd_solver='full')\n","# pca.fit(data)\n","\n","# # fetching the principal components\n","# pca_df = pca.transform(data)\n","# pca_df\n","\n","# # using the principal components to fetch feature importances\n","# # reference - http://benalexkeen.com/principle-component-analysis-in-python/ \n","# def fetch_feature_importance(pca_df, components, cols):\n","  \n","#   num_columns = len(cols)\n","  \n","#   xvector = components[0] * max(pca_df[:,0])\n","#   yvector = components[1] * max(pca_df[:,1])\n","  \n","#   imp_features = { cols[i] : math.sqrt(xvector[i]**2 + yvector[i]**2) for i in range(num_columns) }\n","#   imp_features = sorted(zip(imp_features.values(), imp_features.keys()), reverse=True)\n","# #   print (\"Features by importance:\\n\", imp_features)\n","#   return imp_features\n","\n","# imp_features = fetch_feature_importance(pca_df, pca.components_, data.columns.values)\n","\n","# pca_features = []\n","\n","# for item in imp_features:\n","#   pca_features.append(item[1])\n","  \n","# top_pca_features = pca_features[0:13]\n","\n","# # fetching top 12 features from the dataset\n","# X = data[top_pca_features]\n","# X = X.drop(['user_id'], axis = 1)\n","# y = data.iloc[:, data.columns == 'adopter']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mJ_aTot0Hxqg","colab_type":"code","outputId":"760d885f-beb4-49a9-a9ba-738169919d09","executionInfo":{"status":"ok","timestamp":1554914436554,"user_tz":240,"elapsed":292,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":1969}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>adopter</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>86652</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86653</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86654</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86655</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86656</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86657</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86658</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86659</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86660</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86661</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86662</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86663</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86664</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86665</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86666</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86667</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86668</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86669</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86670</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86671</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86672</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86673</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86674</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86675</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>86676</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86677</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86678</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86679</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86680</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86681</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>86682 rows × 1 columns</p>\n","</div>"],"text/plain":["       adopter\n","0            0\n","1            0\n","2            0\n","3            0\n","4            0\n","5            0\n","6            0\n","7            0\n","8            0\n","9            0\n","10           0\n","11           0\n","12           0\n","13           0\n","14           0\n","15           0\n","16           0\n","17           0\n","18           0\n","19           0\n","20           0\n","21           0\n","22           0\n","23           0\n","24           0\n","25           0\n","26           0\n","27           0\n","28           0\n","29           0\n","...        ...\n","86652        0\n","86653        0\n","86654        0\n","86655        0\n","86656        0\n","86657        0\n","86658        0\n","86659        0\n","86660        0\n","86661        0\n","86662        0\n","86663        0\n","86664        0\n","86665        0\n","86666        0\n","86667        0\n","86668        0\n","86669        0\n","86670        0\n","86671        0\n","86672        0\n","86673        0\n","86674        0\n","86675        1\n","86676        0\n","86677        0\n","86678        0\n","86679        0\n","86680        0\n","86681        0\n","\n","[86682 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":114}]},{"metadata":{"id":"P0wxoC7gWIRy","colab_type":"code","outputId":"98eaec31-0e9f-4f5a-9471-bc8a143f3016","executionInfo":{"status":"ok","timestamp":1554914411458,"user_tz":240,"elapsed":252,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["# # splitting original dataset into features and predictor - uncomment if no PCA is needed\n","# # X = data.iloc[:, data.columns != 'adopter']\n","# # y = data.iloc[:, data.columns == 'adopter']\n","# # \n","# # splitting the original dataset for cross-validation (0.7 train, 0.3 test)\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n","\n","# print (\"Original Data:\")\n","# print (\"Number of train instances: {}\".format(len(X_train)))\n","# print (\"Number of test instances: {}\".format(len(X_test)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Original Data:\n","Number of train instances: 60677\n","Number of test instances: 26005\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"m4-LfIKOVjBN"},"cell_type":"markdown","source":["## SMOTE splitting\n","\n","We'll use SMOTE (Synthetic Minority Oversampling Technique) to create(synthesize) more samples of minority class. The recall score we got earlier might be less as we imputed more than 80% of the data to balance the dataset. "]},{"metadata":{"id":"vcEGpOHQAcx_","colab_type":"text"},"cell_type":"markdown","source":["Before we SMOTE the entire dataset, synthesizing around 58000 new instances of minority will not introduce enough variation in data for the models to learn. \n","\n","We decide that we will include only a subset of the majority class instances and synthsize new instances for minority class using SMOTE. That'll (hopefully) avoid our models from overfitting. "]},{"metadata":{"id":"-T7TUPGcBDEL","colab_type":"code","outputId":"20b84e0a-3987-461f-951e-7a2d782991ee","executionInfo":{"status":"ok","timestamp":1555039058374,"user_tz":240,"elapsed":343,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["# fetching the indices of minority instances\n","adopting_indices = np.array(data[data.adopter == 1].index)\n","\n","# fetching indices of normal instances\n","non_adopting_indices = data[data.adopter == 0].index\n","\n","# randomly select 1540 normal instances to create a partitioned balanced dataset\n","random_non_adopting_indices = np.random.choice(non_adopting_indices,\n","                                            3540,\n","                                            replace = False)\n","random_non_adopting_indices = np.array(random_non_adopting_indices)\n","\n","# combining both the instance groups (minority and the new random set) \n","undersampled_indices = np.concatenate([adopting_indices, random_non_adopting_indices])\n","\n","# creating the undersampled dataset\n","undersampled_data = data.iloc[undersampled_indices, :]\n","\n","# shufling the new dataset\n","undersampled_data = shuffle(undersampled_data, random_state = seed)\n","\n","# storing the features(X) and predictor class(y)\n","X_undersample = undersampled_data.iloc[:, undersampled_data.columns != 'adopter']\n","y_undersample = undersampled_data.iloc[:, undersampled_data.columns == 'adopter']\n","\n","print(\"Number of minority instances: {}\\nNumber of normal instances: {} \\nTotal: {}\".format(len(undersampled_data[undersampled_data.adopter == 1]), \n","                                                                                           len(undersampled_data[undersampled_data.adopter == 0]),\n","                                                                                           len(undersampled_data)))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Number of minority instances: 1540\n","Number of normal instances: 3540 \n","Total: 5080\n"],"name":"stdout"}]},{"metadata":{"id":"CPAesB2iIMmq","colab_type":"text"},"cell_type":"markdown","source":["# PCA\n","\n","The neural net is overfitting for either of the classes (regardless of the sample ration). We'll try extracting top x important features to reduce the number of dimensions our net has to deal with."]},{"metadata":{"id":"4LLVjSv1INib","colab_type":"code","colab":{}},"cell_type":"code","source":["# Let's reduce the feature space to 10 Principal Components\n","pca = PCA(n_components=2, svd_solver='full')\n","pca.fit(undersampled_data)\n","\n","# fetching the principal components\n","pca_df = pca.transform(undersampled_data)\n","pca_df\n","\n","# using the principal components to fetch feature importances\n","# reference - http://benalexkeen.com/principle-component-analysis-in-python/ \n","def fetch_feature_importance(pca_df, components, cols):\n","  \n","  num_columns = len(cols)\n","  \n","  xvector = components[0] * max(pca_df[:,0])\n","  yvector = components[1] * max(pca_df[:,1])\n","  \n","  imp_features = { cols[i] : math.sqrt(xvector[i]**2 + yvector[i]**2) for i in range(num_columns) }\n","  imp_features = sorted(zip(imp_features.values(), imp_features.keys()), reverse=True)\n","#   print (\"Features by importance:\\n\", imp_features)\n","  return imp_features\n","\n","imp_features = fetch_feature_importance(pca_df, pca.components_, data.columns.values)\n","\n","pca_features = []\n","\n","for item in imp_features:\n","  pca_features.append(item[1])\n","  \n","top_pca_features = pca_features[0:13]\n","\n","# fetching top 12 features from the dataset\n","X = undersampled_data[top_pca_features]\n","X = X.drop(['user_id'], axis = 1)\n","y = undersampled_data.iloc[:, undersampled_data.columns == 'adopter']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3oiBRdANBXfN","colab_type":"code","outputId":"af0f173c-2ff9-46e2-a061-565a838e6e0b","executionInfo":{"status":"ok","timestamp":1555039068970,"user_tz":240,"elapsed":282,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["# # splitting original dataset into features and predictor\n","# X = undersampled_data.iloc[:, data.columns != 'adopter']\n","# y = undersampled_data.iloc[:, data.columns == 'adopter']\n","\n","# splitting the original dataset for cross-validation (0.7 train, 0.3 test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n","\n","print (\"Undersampled Data:\")\n","print (\"Number of train instances: {}\".format(len(X_train)))\n","print (\"Number of test instances: {}\".format(len(X_test)))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Undersampled Data:\n","Number of train instances: 3556\n","Number of test instances: 1524\n"],"name":"stdout"}]},{"metadata":{"id":"pe2cR4TFOnWB","colab_type":"code","outputId":"af4f1464-e1c7-49a4-cb39-4a7781ebb1e3","executionInfo":{"status":"ok","timestamp":1555039081658,"user_tz":240,"elapsed":295,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"cell_type":"code","source":["sm = SMOTE(random_state = 12, ratio = None)\n","X_train_smoted_np, y_train_smoted_np = sm.fit_sample(X_train, y_train)\n","# X_train_smoted, y_train_smoted = sm.fit_sample(X_train, y_train.values.ravel())\n","print(type(X_train_smoted_np))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"}]},{"metadata":{"id":"1JZ7DMhwQ3s1","colab_type":"code","outputId":"9e989c80-2eb9-47df-8ca8-8c2795cbeae6","executionInfo":{"status":"ok","timestamp":1555039090135,"user_tz":240,"elapsed":580,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["# # checking the lengths of new training set\n","\n","print (\"Number of SMOTEd instances: {}\".format(len(X_train_smoted_np)))\n","\n","X_train.head()\n","y_train_smoted_non_adopters = y_train_smoted_np[y_train_smoted_np == 1]\n","y_train_smoted_adopters = y_train_smoted_np[y_train_smoted_np == 0]\n","\n","print (\"Number of SMOTEd non-adopters (adopter = 0): {}\".format(len(y_train_smoted_non_adopters)))\n","print (\"Number of SMOTEd adopters (adopter = 1): {}\".format(len(y_train_smoted_adopters)))\n","\n","X_train = X_train_smoted_np\n","y_train = y_train_smoted_np"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Number of SMOTEd instances: 5014\n","Number of SMOTEd non-adopters (adopter = 0): 2507\n","Number of SMOTEd adopters (adopter = 1): 2507\n"],"name":"stdout"}]},{"metadata":{"id":"OQR9mY4pUvEF","colab_type":"text"},"cell_type":"markdown","source":["We now have around 2792 instances each of both the classes, which is better than simple undersampling and having only 3080 instances in all.\n","\n"]},{"metadata":{"id":"6dPpzJElwkIS","colab_type":"text"},"cell_type":"markdown","source":["For now we'll import smoted data from our R scripts since the above is taking time."]},{"metadata":{"id":"Lro-UcZ7yTtv","colab_type":"text"},"cell_type":"markdown","source":["## Building a shallow NN"]},{"metadata":{"id":"GLEn8EgR369x","colab_type":"code","colab":{}},"cell_type":"code","source":["# temp function to plot confusion matrix\n","\n","def plot_conf_matrix(cm, \n","                     classes,\n","                     normalize=False,\n","                     title='Confusion matrix',\n","                     cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    \n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=0)\n","    plt.yticks(tick_marks, classes)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        #print(\"Normalized confusion matrix\")\n","    else:\n","        1#print('Confusion matrix, without normalization')\n","\n","    #print(cm)\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eYAeEKFiSHjW","colab_type":"code","colab":{}},"cell_type":"code","source":["# temp function to plot training accuracy and loss\n","\n","def plot_acc_loss(class_hist):\n","  plt.subplot(211)\n","  plt.title('Loss')\n","  plt.plot(class_hist.history['loss'], label='train')\n","  plt.plot(class_hist.history['val_loss'], label='test')\n","  plt.legend()\n","  \n","  plt.subplot(212)\n","  plt.title('Accuracy')\n","  plt.plot(class_hist.history['acc'], label='train')\n","  plt.plot(class_hist.history['val_acc'], label='test')\n","  plt.legend()\n","  plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lpIxkHYrkMva","colab_type":"code","colab":{}},"cell_type":"code","source":["# Baseline NN with single hidden layer (num of neurons = num of features)\n","# num_neurons = undersampled_data.shape[1] - 1\n","\n","def baseline_nn():\n","  num_neurons = 12\n","  model = Sequential()\t\n","  \n","  # 100 hidden neurons + input neurons \n","#   model.add(Dropout(0.2, input_shape = (undersampled_data.shape[1] - 1, )))\n","\n","  model.add(Dense(num_neurons, input_shape=(X.shape[1],)))\n","  model.add(Dropout(0.1))#    input dropout\n","  model.add(PReLU())\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.5))\n","\n","  model.add(Dense(360))\n","  model.add(PReLU())\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.5))\n","\n","  model.add(Dense(420))\n","  model.add(PReLU())\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.5))\n","\n","  model.add(Dense(1))\n","  model.add(Activation('softmax'))\n","  #opt=SGD(momentum=0.9)\n","  model.compile(loss='binary_crossentropy', optimizer=\"sgd\")\n","  \n","#   model.add(Dense(num_neurons,        \n","#                   input_dim = X.shape[1],\n","#                   kernel_initializer = 'normal', \n","#                   activation = 'tanh',\n","#                   activity_regularizer=l1(0.01)))\n","  \n","#   model.add(Dropout(0.2))\n","  \n","#   model.add(Dense(10, \n","#                   kernel_initializer = 'normal', \n","#                   activation = 'tanh',\n","#                   activity_regularizer=l1(0.01)))\n","  \n","#   model.add(Dropout(0.2))\n","  \n","#   model.add(Dense(1, \n","#                   kernel_initializer = 'normal', \n","#                   activation='sigmoid'))\t\n","  \n","#   model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n","  \n","  return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M2z7uj0ukJar","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"fd625f9e-10a3-404d-be45-906b60e594d0","executionInfo":{"status":"ok","timestamp":1555039310415,"user_tz":240,"elapsed":693,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}}},"cell_type":"code","source":["X.shape[1]-1"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"id":"fzFFo853to5X","colab_type":"code","outputId":"fb557bed-a5d5-4109-a304-d2abd0af60b8","executionInfo":{"status":"error","timestamp":1555039787536,"user_tz":240,"elapsed":36780,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":4079}},"cell_type":"code","source":["# estimator = KerasClassifier(build_fn = baseline_nn, \n","#                             epochs=10, \n","#                             batch_size = 5, \n","#                             verbose=1)\n","\n","classifier = baseline_nn()\n","\n","#class_weights = {0: 1, 1: 10}\n","\n","classifier_history = classifier.fit(X_train, \n","                                    y_train, \n","                                    validation_split=0.33, \n","                                    batch_size = 256, \n","                                    epochs = 100)\n","\n","# plt.plot(classifier_history.history['acc'])\n","plot_acc_loss(classifier_history)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Train on 3359 samples, validate on 1655 samples\n","Epoch 1/100\n","3359/3359 [==============================] - 2s 642us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 2/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 3/100\n","3359/3359 [==============================] - 0s 101us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 4/100\n","3359/3359 [==============================] - 0s 99us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 5/100\n","3359/3359 [==============================] - 0s 98us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 6/100\n","3359/3359 [==============================] - 0s 99us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 7/100\n","3359/3359 [==============================] - 0s 101us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 8/100\n","3359/3359 [==============================] - 0s 100us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 9/100\n","3359/3359 [==============================] - 0s 100us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 10/100\n","3359/3359 [==============================] - 0s 102us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 11/100\n","3359/3359 [==============================] - 0s 102us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 12/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 13/100\n","3359/3359 [==============================] - 0s 99us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 14/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 15/100\n","3359/3359 [==============================] - 0s 96us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 16/100\n","3359/3359 [==============================] - 0s 98us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 17/100\n","3359/3359 [==============================] - 0s 98us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 18/100\n","3359/3359 [==============================] - 0s 101us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 19/100\n","3359/3359 [==============================] - 0s 105us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 20/100\n","3359/3359 [==============================] - 0s 96us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 21/100\n","3359/3359 [==============================] - 0s 100us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 22/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 23/100\n","3359/3359 [==============================] - 0s 102us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 24/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 25/100\n","3359/3359 [==============================] - 0s 99us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 26/100\n","3359/3359 [==============================] - 0s 94us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 27/100\n","3359/3359 [==============================] - 0s 98us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 28/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 29/100\n","3359/3359 [==============================] - 0s 93us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 30/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 31/100\n","3359/3359 [==============================] - 0s 99us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 32/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 33/100\n","3359/3359 [==============================] - 0s 94us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 34/100\n","3359/3359 [==============================] - 0s 94us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 35/100\n","3359/3359 [==============================] - 0s 92us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 36/100\n","3359/3359 [==============================] - 0s 93us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 37/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 38/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 39/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 40/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 41/100\n","3359/3359 [==============================] - 0s 96us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 42/100\n","3359/3359 [==============================] - 0s 92us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 43/100\n","3359/3359 [==============================] - 0s 93us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 44/100\n","3359/3359 [==============================] - 0s 94us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 45/100\n","3359/3359 [==============================] - 0s 93us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 46/100\n","3359/3359 [==============================] - 0s 98us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 47/100\n","3359/3359 [==============================] - 0s 96us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 48/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 49/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 50/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 51/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 52/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 53/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 54/100\n","3359/3359 [==============================] - 0s 94us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 55/100\n","3359/3359 [==============================] - 0s 92us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 56/100\n","3359/3359 [==============================] - 0s 96us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 57/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 58/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 59/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 60/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 61/100\n","3359/3359 [==============================] - 0s 94us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 62/100\n","3359/3359 [==============================] - 0s 94us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 63/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 64/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 65/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 66/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 67/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 68/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 69/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 70/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 71/100\n","3359/3359 [==============================] - 0s 96us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 72/100\n","3359/3359 [==============================] - 0s 98us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 73/100\n","3359/3359 [==============================] - 0s 98us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 74/100\n","3359/3359 [==============================] - 0s 98us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 75/100\n","3359/3359 [==============================] - 0s 94us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 76/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 77/100\n","3359/3359 [==============================] - 0s 99us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 78/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 79/100\n","3359/3359 [==============================] - 0s 93us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 80/100\n","3359/3359 [==============================] - 0s 92us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 81/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 82/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 83/100\n","3359/3359 [==============================] - 0s 98us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 84/100\n","3359/3359 [==============================] - 0s 96us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 85/100\n","3359/3359 [==============================] - 0s 96us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 86/100\n","3359/3359 [==============================] - 0s 94us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 87/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 88/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 89/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 90/100\n","3359/3359 [==============================] - 0s 96us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 91/100\n","3359/3359 [==============================] - 0s 99us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 92/100\n","3359/3359 [==============================] - 0s 96us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 93/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 94/100\n","3359/3359 [==============================] - 0s 99us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 95/100\n","3359/3359 [==============================] - 0s 98us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 96/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 97/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 98/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 99/100\n","3359/3359 [==============================] - 0s 97us/step - loss: 11.2674 - val_loss: 1.2812\n","Epoch 100/100\n","3359/3359 [==============================] - 0s 95us/step - loss: 11.2674 - val_loss: 1.2812\n"],"name":"stdout"},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-d5046cd1a239>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# plt.plot(classifier_history.history['acc'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplot_acc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-0f5439f0bfd0>\u001b[0m in \u001b[0;36mplot_acc_loss\u001b[0;34m(class_hist)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m212\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'acc'"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAegAAAFZCAYAAABTxrzcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAL+v/ow57yEmVElgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 576x396 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"H8yxYiSHa227","colab_type":"code","outputId":"0b5fc36b-d4ce-4b99-cfe5-bcbe476cf38d","executionInfo":{"status":"ok","timestamp":1555039851500,"user_tz":240,"elapsed":560,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":646}},"cell_type":"code","source":["classifier.summary()"],"execution_count":36,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_26 (Dense)             (None, 12)                156       \n","_________________________________________________________________\n","dropout_20 (Dropout)         (None, 12)                0         \n","_________________________________________________________________\n","p_re_lu_6 (PReLU)            (None, 12)                12        \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 12)                48        \n","_________________________________________________________________\n","dropout_21 (Dropout)         (None, 12)                0         \n","_________________________________________________________________\n","dense_27 (Dense)             (None, 360)               4680      \n","_________________________________________________________________\n","p_re_lu_7 (PReLU)            (None, 360)               360       \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 360)               1440      \n","_________________________________________________________________\n","dropout_22 (Dropout)         (None, 360)               0         \n","_________________________________________________________________\n","dense_28 (Dense)             (None, 420)               151620    \n","_________________________________________________________________\n","p_re_lu_8 (PReLU)            (None, 420)               420       \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 420)               1680      \n","_________________________________________________________________\n","dropout_23 (Dropout)         (None, 420)               0         \n","_________________________________________________________________\n","dense_29 (Dense)             (None, 1)                 421       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 1)                 0         \n","=================================================================\n","Total params: 160,837\n","Trainable params: 159,253\n","Non-trainable params: 1,584\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"rsObgt1yVo3W","colab_type":"code","outputId":"37477b5e-fdae-42e6-92ae-1329af1f6531","executionInfo":{"status":"ok","timestamp":1555039855648,"user_tz":240,"elapsed":1034,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":258}},"cell_type":"code","source":["y_pred = classifier.predict_classes(X_test)\n","# y_pred = (y_pred > 0.5)\n","y_pred\n","# cm = confusion_matrix(y_test, y_pred)\n","# plot_conf_matrix(cm, [1,0])\n","\n","print(classification_report(y_test, y_pred))\n","print(confusion_matrix(y_test, y_pred))\n"],"execution_count":37,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00      1033\n","           1       0.32      1.00      0.49       491\n","\n","   micro avg       0.32      0.32      0.32      1524\n","   macro avg       0.16      0.50      0.24      1524\n","weighted avg       0.10      0.32      0.16      1524\n","\n","[[   0 1033]\n"," [   0  491]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n"],"name":"stderr"}]},{"metadata":{"id":"dGXyg1hTQNGO","colab_type":"code","colab":{}},"cell_type":"code","source":["#  y_test.shape[0]\n","y_pred"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fGPqMsx53_vv","colab_type":"code","colab":{}},"cell_type":"code","source":["# fetching metrics\n","recall_val = recall_score(y_test, y_pred)\n","f1_val = f1_score(y_test, y_pred)\n","acc_val = accuracy_score(y_test, y_pred)\n","precision_val = precision_score(y_test, y_pred)\n","\n","print('Accuracy: %f' % acc_val)\n","print('Precision: %f' % precision_val)\n","print('Recall: %f' % recall_val)\n","print('F1 score: %f' % f1_val)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q-srl2siaBJX","colab_type":"code","colab":{}},"cell_type":"code","source":["# unseen_data = pd.read_csv('https://drive.google.com/uc?export=view&id=1yVPwqGQC2gkhF2bcbue9j3184ryAJRtG')\n","# y_pred = classifier.predict_classes(unseen_data)\n","\n","# np.savetxt(\"predictions.csv\", y_pred , delimiter=\",\")\n","# from google.colab import files\n","# files.download('predictions.csv')"],"execution_count":0,"outputs":[]}]}