{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"metadata":{"id":"V1rh8exUxxpk","colab_type":"text"},"cell_type":"markdown","source":["\n","## **Adopter Prediction Challenge**\n","\n"," ~ Ankita, Ashok, Kaydee, Young\n"," \n"," ---\n","\n","Website XYZ, a music-listening social networking website, follows the “freemium” business model. The website offers basic services for free, and provides a number of additional premium capabilities for a monthly subscription fee. We are interested in predicting which people would be likely to convert from free users to premium subscribers in the next 6 month period, if they are targeted by our promotional campaign.\n","\n","### Dataset\n","\n","We have a dataset from the previous marketing campaign which targeted a number of non-subscribers.\n","\n","Features: \n","\n","```\n","1.   adopter (predictor class)\n","2.   user_id\n","3.   age\n","4.   male\n","5.   friend_cnt\n","6.   avg_friend_age\n","7.   avg_friend_male\n","8.   friend_country_cnt\n","9.   subscriber_friend_cnt\n","10.   songsListened\n","11.   lovedTracks\n","12.   posts\n","13.   playlists\n","14.   shouts\n","15.   good_country\n","16.   tenure\n","17.   *other delta variables*\n","```\n","\n","\n","\n","### Task\n","\n","The task is to build the best predictive model for the next marketing campaign, i.e., for predicting likely `adopters` (that is, which current non- subscribers are likely to respond to the marketing campaign and sign up for the premium service within 6 months after the campaign).\n","\n","---"]},{"metadata":{"id":"c0lAOQ2b0Xvf","colab_type":"text"},"cell_type":"markdown","source":["### EDA\n","\n","Performing some rudimentary EDA"]},{"metadata":{"id":"7BFSsGGrrAWo","colab_type":"code","outputId":"73aebadb-3ec4-4001-92a2-102044f3201e","executionInfo":{"status":"ok","timestamp":1553895676457,"user_tz":240,"elapsed":3507,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"cell_type":"code","source":["!pip3 install sklearn"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.20.3)\n","Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.14.6)\n","Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.1.0)\n"],"name":"stdout"}]},{"metadata":{"id":"z5jYBuZXxrl-","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import itertools\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import cross_val_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","\n","from google.colab import drive\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import KFold, cross_val_score\n","from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, classification_report, recall_score, f1_score, accuracy_score, precision_score\n","\n","from imblearn.over_sampling import SMOTE"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Qbw2hXELhkxW","colab_type":"code","colab":{}},"cell_type":"code","source":["# setting fixed seed value for consistency in results\n","seed = 7\n","np.random.seed(seed)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"biD6vPF8wkO_","colab_type":"code","outputId":"69e42e81-6d90-42e4-8b8d-44857da955c7","executionInfo":{"status":"ok","timestamp":1553895677700,"user_tz":240,"elapsed":4708,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["# drive.mount('/content/drive/')\n","\n","# original dataset\n","data = pd.read_csv('https://drive.google.com/uc?export=view&id=1wctM0dYDj839zp6sTlFnDgCmFspXhDuW')\n","\n","# rose_data from the R script\n","# data = pd.read_csv('https://drive.google.com/uc?export=view&id=14wilOFigXttteZAt5oUHT9fh1m5LhnJj')\n","\n","data.adopter.value_counts()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    85142\n","1     1540\n","Name: adopter, dtype: int64"]},"metadata":{"tags":[]},"execution_count":84}]},{"metadata":{"id":"l8_QqI5UiMXZ","colab_type":"text"},"cell_type":"markdown","source":["Checking to see if any features (especially adopter) needs to be encoded as int"]},{"metadata":{"id":"FF3XVIzsiEQe","colab_type":"code","outputId":"f119b45d-f2ed-43f7-e9d6-03c035fc891c","executionInfo":{"status":"ok","timestamp":1553895677702,"user_tz":240,"elapsed":4696,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":493}},"cell_type":"code","source":["data.dtypes"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["user_id                          int64\n","age                              int64\n","male                             int64\n","friend_cnt                       int64\n","avg_friend_age                 float64\n","avg_friend_male                float64\n","friend_country_cnt               int64\n","subscriber_friend_cnt            int64\n","songsListened                    int64\n","lovedTracks                      int64\n","posts                            int64\n","playlists                        int64\n","shouts                           int64\n","delta_friend_cnt                 int64\n","delta_avg_friend_age           float64\n","delta_avg_friend_male          float64\n","delta_friend_country_cnt         int64\n","delta_subscriber_friend_cnt      int64\n","delta_songsListened              int64\n","delta_lovedTracks                int64\n","delta_posts                      int64\n","delta_playlists                  int64\n","delta_shouts                     int64\n","tenure                           int64\n","good_country                     int64\n","delta_good_country               int64\n","adopter                          int64\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":85}]},{"metadata":{"id":"P0wxoC7gWIRy","colab_type":"code","outputId":"0c445bbc-6441-4bd3-a81d-5b170a1a20cb","executionInfo":{"status":"ok","timestamp":1553895677704,"user_tz":240,"elapsed":4687,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["# splitting original dataset into features and predictor\n","X = data.iloc[:, data.columns != 'adopter']\n","y = data.iloc[:, data.columns == 'adopter']\n","\n","# splitting the original dataset for cross-validation (0.7 train, 0.3 test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n","\n","print (\"Original Data:\")\n","print (\"Number of train instances: {}\".format(len(X_train)))\n","print (\"Number of test instances: {}\".format(len(X_test)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Original Data:\n","Number of train instances: 60677\n","Number of test instances: 26005\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"m4-LfIKOVjBN"},"cell_type":"markdown","source":["## SMOTE splitting\n","\n","We'll use SMOTE (Synthetic Minority Oversampling Technique) to create(synthesize) more samples of minority class. The recall score we got earlier might be less as we imputed more than 80% of the data to balance the dataset. "]},{"metadata":{"id":"vcEGpOHQAcx_","colab_type":"text"},"cell_type":"markdown","source":["Before we SMOTE the entire dataset, synthesizing around 58000 new instances of minority will not introduce enough variation in data for the models to learn. \n","\n","We decide that we will include only a subset of the majority class instances (4000) and synthsize 4000-1540=2460 new instances for minority class using SMOTE. That'll (hopefully) avoid our models from overfitting. "]},{"metadata":{"id":"-T7TUPGcBDEL","colab_type":"code","outputId":"506f3b50-2c18-4643-8515-2e3b7bc77e0b","executionInfo":{"status":"ok","timestamp":1553899232216,"user_tz":240,"elapsed":281,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["# fetching the indices of minority instances\n","adopting_indices = np.array(data[data.adopter == 1].index)\n","\n","# fetching indices of normal instances\n","non_adopting_indices = data[data.adopter == 0].index\n","\n","# randomly select 1540 normal instances to create a partitioned balanced dataset\n","random_non_adopting_indices = np.random.choice(non_adopting_indices,\n","                                            1540,\n","                                            replace = False)\n","random_non_adopting_indices = np.array(random_non_adopting_indices)\n","\n","# combining both the instance groups (minority and the new random set) \n","undersampled_indices = np.concatenate([adopting_indices, random_non_adopting_indices])\n","\n","# creating the undersampled dataset\n","undersampled_data = data.iloc[undersampled_indices, :]\n","\n","# storing the features(X) and predictor class(y)\n","X_undersample = undersampled_data.iloc[:, undersampled_data.columns != 'adopter']\n","y_undersample = undersampled_data.iloc[:, undersampled_data.columns == 'adopter']\n","\n","print(\"Number of minority instances: {}\\nNumber of normal instances: {} \\nTotal: {}\".format(len(undersampled_data[undersampled_data.adopter == 1]), \n","                                                                                           len(undersampled_data[undersampled_data.adopter == 0]),\n","                                                                                           len(undersampled_data)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of minority instances: 1540\n","Number of normal instances: 1540 \n","Total: 3080\n"],"name":"stdout"}]},{"metadata":{"id":"3oiBRdANBXfN","colab_type":"code","outputId":"76c00f69-3cfd-49b5-cfb2-a8d455808d79","executionInfo":{"status":"ok","timestamp":1553899235883,"user_tz":240,"elapsed":346,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["# splitting original dataset into features and predictor\n","X = undersampled_data.iloc[:, data.columns != 'adopter']\n","y = undersampled_data.iloc[:, data.columns == 'adopter']\n","\n","# splitting the original dataset for cross-validation (0.7 train, 0.3 test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n","\n","print (\"Undersampled Data:\")\n","print (\"Number of train instances: {}\".format(len(X_train)))\n","print (\"Number of test instances: {}\".format(len(X_test)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Undersampled Data:\n","Number of train instances: 2156\n","Number of test instances: 924\n"],"name":"stdout"}]},{"metadata":{"id":"pe2cR4TFOnWB","colab_type":"code","outputId":"88b44ccd-af2f-4ccf-cb78-fd168633543a","executionInfo":{"status":"ok","timestamp":1553895677707,"user_tz":240,"elapsed":4651,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"cell_type":"code","source":["sm = SMOTE(random_state = 12, ratio = None)\n","X_train_smoted_np, y_train_smoted_np = sm.fit_sample(X_train, y_train)\n","# X_train_smoted, y_train_smoted = sm.fit_sample(X_train, y_train.values.ravel())\n","print(type(X_train_smoted_np))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"}]},{"metadata":{"id":"1JZ7DMhwQ3s1","colab_type":"code","outputId":"8ac0dc01-46a3-4908-adbe-0c76c5f4c40f","executionInfo":{"status":"ok","timestamp":1553895677859,"user_tz":240,"elapsed":4794,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["# checking the lengths of new training set\n","\n","print (\"Number of SMOTEd instances: {}\".format(len(X_train_smoted_np)))\n","\n","X_train.head()\n","y_train_smoted_non_adopters = y_train_smoted_np[y_train_smoted_np == 1]\n","y_train_smoted_adopters = y_train_smoted_np[y_train_smoted_np == 0]\n","\n","print (\"Number of SMOTEd non-adopters (adopter = 0): {}\".format(len(y_train_smoted_non_adopters)))\n","print (\"Number of SMOTEd adopters (adopter = 1): {}\".format(len(y_train_smoted_adopters)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of SMOTEd instances: 8410\n","Number of SMOTEd non-adopters (adopter = 0): 4205\n","Number of SMOTEd adopters (adopter = 1): 4205\n"],"name":"stdout"}]},{"metadata":{"id":"OQR9mY4pUvEF","colab_type":"text"},"cell_type":"markdown","source":["We now have around 2792 instances each of both the classes, which is better than simple undersampling and having only 3080 instances in all.\n","\n"]},{"metadata":{"id":"6dPpzJElwkIS","colab_type":"text"},"cell_type":"markdown","source":["For now we'll import smoted data from our R scripts since the above is taking time."]},{"metadata":{"id":"Lro-UcZ7yTtv","colab_type":"text"},"cell_type":"markdown","source":["## Building a shallow NN"]},{"metadata":{"id":"GLEn8EgR369x","colab_type":"code","colab":{}},"cell_type":"code","source":["# temp function to plot confusion matrix\n","\n","def plot_conf_matrix(cm, \n","                     classes,\n","                     normalize=False,\n","                     title='Confusion matrix',\n","                     cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    \n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=0)\n","    plt.yticks(tick_marks, classes)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        #print(\"Normalized confusion matrix\")\n","    else:\n","        1#print('Confusion matrix, without normalization')\n","\n","    #print(cm)\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eYAeEKFiSHjW","colab_type":"code","colab":{}},"cell_type":"code","source":["# temp function to plot training accuracy and loss\n","\n","def plot_acc_loss(class_hist):\n","  plt.subplot(211)\n","  plt.title('Loss')\n","  plt.plot(class_hist.history['loss'], label='train')\n","  plt.plot(class_hist.history['val_loss'], label='test')\n","  plt.legend()\n","  \n","  plt.subplot(212)\n","  plt.title('Accuracy')\n","  plt.plot(class_hist.history['acc'], label='train')\n","  plt.plot(class_hist.history['val_acc'], label='test')\n","  plt.legend()\n","  plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lpIxkHYrkMva","colab_type":"code","colab":{}},"cell_type":"code","source":["# Baseline NN with single hidden layer (num of neurons = num of features)\n","# num_neurons = undersampled_data.shape[1] - 1\n","num_neurons = 4\n","def baseline_nn():\n","  model = Sequential()\t\n","  \n","  # 5 hidden neurons + input neurons = num of dimensions\n","  model.add(Dense(num_neurons, \n","                  input_dim = undersampled_data.shape[1] - 1, \n","                  kernel_initializer = 'normal', \n","                  activation = 'relu'))\n","  \n","  model.add(Dense(3, \n","                  kernel_initializer = 'normal', \n","                  activation = 'relu'))\n","  \n","  model.add(Dense(1, \n","                  kernel_initializer = 'normal', \n","                  activation='sigmoid'))\t\n","  \n","  model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n","  \n","  return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fzFFo853to5X","colab_type":"code","outputId":"a68d1360-d651-43ab-8711-6b9c293b363a","executionInfo":{"status":"error","timestamp":1553899795577,"user_tz":240,"elapsed":10260,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":1646}},"cell_type":"code","source":["# estimator = KerasClassifier(build_fn = baseline_nn, \n","#                             epochs=10, \n","#                             batch_size = 5, \n","#                             verbose=1)\n","\n","classifier = baseline_nn()\n","\n","class_weights = {0: 1.,\n","                 1: 50.}\n","\n","classifier_history = classifier.fit(X_train, \n","                                    y_train, \n","                                    validation_split=0.33, \n","                                    batch_size = 5, \n","                                    epochs = 100,\n","                                   class_weight = class_weights)\n","\n","plot_acc_loss(classifier_history)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 1444 samples, validate on 712 samples\n","Epoch 1/100\n","1444/1444 [==============================] - 3s 2ms/step - loss: 5.9028 - acc: 0.4765 - val_loss: 3.7109 - val_acc: 0.5000\n","Epoch 2/100\n","1444/1444 [==============================] - 1s 374us/step - loss: 3.5927 - acc: 0.4758 - val_loss: 3.7671 - val_acc: 0.5000\n","Epoch 3/100\n","1444/1444 [==============================] - 0s 345us/step - loss: 3.4879 - acc: 0.4758 - val_loss: 3.2012 - val_acc: 0.5000\n","Epoch 4/100\n","1444/1444 [==============================] - 0s 338us/step - loss: 3.4382 - acc: 0.4758 - val_loss: 2.9537 - val_acc: 0.5000\n","Epoch 5/100\n","1444/1444 [==============================] - 0s 325us/step - loss: 3.6646 - acc: 0.4751 - val_loss: 2.9553 - val_acc: 0.5000\n","Epoch 6/100\n","1444/1444 [==============================] - 0s 326us/step - loss: 3.4784 - acc: 0.4771 - val_loss: 2.8877 - val_acc: 0.5000\n","Epoch 7/100\n","1444/1444 [==============================] - 0s 322us/step - loss: 4.0818 - acc: 0.4737 - val_loss: 2.9110 - val_acc: 0.5000\n","Epoch 8/100\n","1444/1444 [==============================] - 0s 326us/step - loss: 4.1583 - acc: 0.4806 - val_loss: 2.8259 - val_acc: 0.5000\n","Epoch 9/100\n","1444/1444 [==============================] - 0s 334us/step - loss: 4.6853 - acc: 0.4751 - val_loss: 3.4479 - val_acc: 0.5000\n","Epoch 10/100\n","1444/1444 [==============================] - 0s 328us/step - loss: 3.5716 - acc: 0.4771 - val_loss: 2.9918 - val_acc: 0.5000\n","Epoch 11/100\n","1444/1444 [==============================] - 0s 327us/step - loss: 4.4021 - acc: 0.4758 - val_loss: 3.1209 - val_acc: 0.5000\n","Epoch 12/100\n","1444/1444 [==============================] - 0s 329us/step - loss: 4.7240 - acc: 0.4771 - val_loss: 3.3160 - val_acc: 0.5000\n","Epoch 13/100\n","1444/1444 [==============================] - 0s 323us/step - loss: 5.9298 - acc: 0.4730 - val_loss: 5.6485 - val_acc: 0.5000\n","Epoch 14/100\n","1444/1444 [==============================] - 0s 330us/step - loss: 5.3661 - acc: 0.4799 - val_loss: 3.3210 - val_acc: 0.5000\n","Epoch 15/100\n","1444/1444 [==============================] - 0s 323us/step - loss: 6.7276 - acc: 0.4744 - val_loss: 3.1237 - val_acc: 0.5000\n","Epoch 16/100\n"," 610/1444 [===========>..................] - ETA: 0s - loss: 4.4103 - acc: 0.4607"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-120-bec50f20b583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                    class_weight = class_weights)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplot_acc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m    119\u001b[0m            (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   4117\u001b[0m     \"\"\"\n\u001b[1;32m   4118\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 4119\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   4120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   4031\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4033\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4034\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   4170\u001b[0m         \u001b[0;31m# warn and return nans like mean would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4171\u001b[0m         \u001b[0mrout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_median_nancheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4174\u001b[0m         \u001b[0;31m# if there are no nans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/utils.py\u001b[0m in \u001b[0;36m_median_nancheck\u001b[0;34m(data, result, axis, out)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m     \u001b[0;31m# masked NaN values are ok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misMaskedArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"H8yxYiSHa227","colab_type":"code","outputId":"358952ef-5c1a-4521-c2a1-41774ce6c2f5","executionInfo":{"status":"ok","timestamp":1553896027243,"user_tz":240,"elapsed":303,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"cell_type":"code","source":["classifier.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_54 (Dense)             (None, 5)                 135       \n","_________________________________________________________________\n","dense_55 (Dense)             (None, 3)                 18        \n","_________________________________________________________________\n","dense_56 (Dense)             (None, 1)                 4         \n","=================================================================\n","Total params: 157\n","Trainable params: 157\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"rsObgt1yVo3W","colab_type":"code","outputId":"78b8680c-c09b-4107-929d-bc24f62ab355","executionInfo":{"status":"ok","timestamp":1553899031374,"user_tz":240,"elapsed":275,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"cell_type":"code","source":["y_pred = classifier.predict_classes(X_test)\n","# y_pred = (y_pred > 0.5)\n","y_pred\n","# cm = confusion_matrix(y_test, y_pred)\n","# plot_conf_matrix(cm, [1,0])\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0],\n","       [0],\n","       [0],\n","       ...,\n","       [0],\n","       [0],\n","       [0]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":109}]},{"metadata":{"id":"dGXyg1hTQNGO","colab_type":"code","colab":{}},"cell_type":"code","source":["# y_test.shape[0]\n","# y_pred"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fGPqMsx53_vv","colab_type":"code","outputId":"ea048fbc-926a-417a-fb52-130055e8c11e","executionInfo":{"status":"ok","timestamp":1553899048742,"user_tz":240,"elapsed":291,"user":{"displayName":"Ashok Patel","photoUrl":"","userId":"00246010457305653101"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"cell_type":"code","source":["# fetching metrics\n","recall_val = recall_score(y_test, y_pred)\n","f1_val = f1_score(y_test, y_pred)\n","acc_val = accuracy_score(y_test, y_pred)\n","precision_val = precision_score(y_test, y_pred)\n","\n","print('Accuracy: %f' % acc_val)\n","print('Precision: %f' % precision_val)\n","print('Recall: %f' % recall_val)\n","print('F1 score: %f' % f1_val)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy: 0.793546\n","Precision: 0.000000\n","Recall: 0.000000\n","F1 score: 0.000000\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n"],"name":"stderr"}]}]}